{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK2p8A6RlCjC",
        "outputId": "66708e80-5781-4029-b3b7-36d59d0338c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "# !pip install fasttext\n",
        "# Word Embedding using FastText\n",
        "import fasttext.util\n",
        "fasttext.util.download_model('ar', if_exists='ignore')  \n",
        "ft = fasttext.load_model('cc.ar.300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "0AzpB7X20nQv",
        "outputId": "6659e656-de3e-4ce4-8a06-5e6db1fee7d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "300\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "print(ft.get_dimension())\n",
        "# reduce the dimension of the word embedding from 300 to 100\n",
        "fasttext.util.reduce_model(ft, 100)\n",
        "print(ft.get_dimension())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kihZk8Y-4tgH",
        "outputId": "fb30bac3-67ee-4154-bc2e-8b26491f210a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.01018494 -0.08594008 -0.03731866 -0.00024127  0.04777642 -0.00496229\n",
            "  0.06186691  0.02239722 -0.0280445   0.04849716 -0.00795461 -0.02634357\n",
            "  0.01323329 -0.02175279  0.03655794 -0.01601862 -0.01084875  0.01393491\n",
            " -0.03315404  0.0335445   0.01913922 -0.02036594 -0.00192303 -0.00421568\n",
            "  0.01183395  0.01175373 -0.07322915  0.08777917  0.00460946 -0.05397879\n",
            " -0.04420993 -0.01738087 -0.01531424 -0.02648391  0.05191071 -0.06218194\n",
            "  0.03248445 -0.03084662  0.02021079 -0.03369771 -0.01912928  0.00776838\n",
            " -0.02871501  0.00045804  0.01323607  0.01341687  0.03769046 -0.00100606\n",
            "  0.03073437 -0.02756213  0.02987276  0.00607357 -0.0034104   0.00598877\n",
            " -0.04017798 -0.02268266  0.04346691 -0.00163789  0.03622608  0.00370311\n",
            " -0.03838527  0.01520885  0.00647131 -0.02734641  0.01213152  0.03940092\n",
            "  0.04791509 -0.01371275 -0.00985732 -0.00985206  0.04072648 -0.01279194\n",
            "  0.02949059  0.0199767   0.01000008  0.0091176  -0.03566917  0.03153419\n",
            " -0.05023986 -0.02361483  0.04186894  0.01141178 -0.01122559  0.00246087\n",
            " -0.02246428 -0.03210542 -0.01676525  0.00943948 -0.02476867  0.00366258\n",
            " -0.01090576 -0.03253023 -0.01524031  0.03003313 -0.00507037 -0.02867209\n",
            "  0.0299578   0.04028277 -0.03969923  0.0278273 ]\n",
            "(100,)\n"
          ]
        }
      ],
      "source": [
        "print(ft.get_word_vector('الشوق شوق')) \n",
        "print(ft.get_word_vector('الشوق شوق').shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "uX5cElIU8FI1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from scipy.stats import skew\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "y0JN8uMI5JKY",
        "outputId": "79da4f5d-0846-4711-9aaa-e1c092db9b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6702, 6)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>stance</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>dialect</th>\n",
              "      <th>cleaned_text_emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...</td>\n",
              "      <td>celebrity</td>\n",
              "      <td>1</td>\n",
              "      <td>بيل غيتس تلقي لقاح كوفيد19 من غير تصوير ابر و ...</td>\n",
              "      <td>Gulf</td>\n",
              "      <td>بيل غيتس تلقي لقاح كوفيد19 من غير تصوير ابر و ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "      <td>وزير صح حد يوم تحديد هل بمؤتمروا صحفي كان ما ع...</td>\n",
              "      <td>Levant</td>\n",
              "      <td>وزير صح حد يوم تحديد هل بمؤتمروا صحفي كان ما ع...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "      <td>قول رح يكونو اد مسؤولي ب لبنان ما وصل لقاح ؟ ا...</td>\n",
              "      <td>Modern Standard Arabic</td>\n",
              "      <td>قول رح يكونو اد مسؤولي ب لبنان ما وصل لقاح ؟ ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...</td>\n",
              "      <td>celebrity</td>\n",
              "      <td>1</td>\n",
              "      <td>تركيا . . وزير صح فخر دين قوجة تلقي اول جرع من...</td>\n",
              "      <td>Maghreb</td>\n",
              "      <td>تركيا . . وزير صح فخر دين قوجة تلقي اول جرع من...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...</td>\n",
              "      <td>personal</td>\n",
              "      <td>0</td>\n",
              "      <td>وئام وهاب شتم دول خليجي في كل طل اعلامي تسافه ...</td>\n",
              "      <td>Gulf</td>\n",
              "      <td>وئام وهاب شتم دول خليجي في كل طل اعلامي تسافه ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   category  stance  \\\n",
              "0  بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...  celebrity       1   \n",
              "1  وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...  info_news       1   \n",
              "2  قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...  info_news       1   \n",
              "3  #تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...  celebrity       1   \n",
              "4  وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...   personal       0   \n",
              "\n",
              "                                        cleaned_text                 dialect  \\\n",
              "0  بيل غيتس تلقي لقاح كوفيد19 من غير تصوير ابر و ...                    Gulf   \n",
              "1  وزير صح حد يوم تحديد هل بمؤتمروا صحفي كان ما ع...                  Levant   \n",
              "2  قول رح يكونو اد مسؤولي ب لبنان ما وصل لقاح ؟ ا...  Modern Standard Arabic   \n",
              "3  تركيا . . وزير صح فخر دين قوجة تلقي اول جرع من...                 Maghreb   \n",
              "4  وئام وهاب شتم دول خليجي في كل طل اعلامي تسافه ...                    Gulf   \n",
              "\n",
              "                                  cleaned_text_emoji  \n",
              "0  بيل غيتس تلقي لقاح كوفيد19 من غير تصوير ابر و ...  \n",
              "1  وزير صح حد يوم تحديد هل بمؤتمروا صحفي كان ما ع...  \n",
              "2  قول رح يكونو اد مسؤولي ب لبنان ما وصل لقاح ؟ ا...  \n",
              "3  تركيا . . وزير صح فخر دين قوجة تلقي اول جرع من...  \n",
              "4  وئام وهاب شتم دول خليجي في كل طل اعلامي تسافه ...  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train = pd.read_csv('./Dataset/cleaned_train.csv')\n",
        "print(df_train.shape)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(991, 6)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>stance</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>dialect</th>\n",
              "      <th>cleaned_text_emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#مريم_رجوي: &lt;LF&gt;حظر خامنئي المجرم شراء #لقاح_ك...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "      <td>مريم رجو : حظر خامنئي مجرم شراء لقاح كور عد مج...</td>\n",
              "      <td>Modern Standard Arabic</td>\n",
              "      <td>مريم رجو : حظر خامنئي مجرم شراء لقاح كور عد مج...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#الصحة:&lt;LF&gt;•تم إعطاء 259.530 جرعة من لقاح #كور...</td>\n",
              "      <td>plan</td>\n",
              "      <td>1</td>\n",
              "      <td>صح : • تم اعطاء 259 . 530 جرع من لقاح كور • اه...</td>\n",
              "      <td>Modern Standard Arabic</td>\n",
              "      <td>صح : • تم اعطاء 259 . 530 جرع من لقاح كور • اه...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#خادم_الحرمين - حفظه الله - يتلقى الجرعة الأول...</td>\n",
              "      <td>celebrity</td>\n",
              "      <td>1</td>\n",
              "      <td>خادم حرم حفظ الله تلقي جرع اولي من لقاح كور كو...</td>\n",
              "      <td>Gulf</td>\n",
              "      <td>خادم حرم حفظ الله تلقي جرع اولي من لقاح كور كو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#الصحه_العالميه: لقاحات #كورونا آمنة ولا خوف م...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "      <td>صح عالمي : لقاحات كور امن ولا خوف من . . و كوف...</td>\n",
              "      <td>Maghreb</td>\n",
              "      <td>صح عالمي : لقاحات كور امن ولا خوف من . . و كوف...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#وزيرة_الصحة \"#هالة_زايد\" تقول إنه يجرى مراجعة...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "      <td>وزير صح هال زايد قول ان جري مراجع خطوط انتاج ش...</td>\n",
              "      <td>Modern Standard Arabic</td>\n",
              "      <td>وزير صح هال زايد قول ان جري مراجع خطوط انتاج ش...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   category  stance  \\\n",
              "0  #مريم_رجوي: <LF>حظر خامنئي المجرم شراء #لقاح_ك...  info_news       1   \n",
              "1  #الصحة:<LF>•تم إعطاء 259.530 جرعة من لقاح #كور...       plan       1   \n",
              "2  #خادم_الحرمين - حفظه الله - يتلقى الجرعة الأول...  celebrity       1   \n",
              "3  #الصحه_العالميه: لقاحات #كورونا آمنة ولا خوف م...  info_news       1   \n",
              "4  #وزيرة_الصحة \"#هالة_زايد\" تقول إنه يجرى مراجعة...  info_news       1   \n",
              "\n",
              "                                        cleaned_text                 dialect  \\\n",
              "0  مريم رجو : حظر خامنئي مجرم شراء لقاح كور عد مج...  Modern Standard Arabic   \n",
              "1  صح : • تم اعطاء 259 . 530 جرع من لقاح كور • اه...  Modern Standard Arabic   \n",
              "2  خادم حرم حفظ الله تلقي جرع اولي من لقاح كور كو...                    Gulf   \n",
              "3  صح عالمي : لقاحات كور امن ولا خوف من . . و كوف...                 Maghreb   \n",
              "4  وزير صح هال زايد قول ان جري مراجع خطوط انتاج ش...  Modern Standard Arabic   \n",
              "\n",
              "                                  cleaned_text_emoji  \n",
              "0  مريم رجو : حظر خامنئي مجرم شراء لقاح كور عد مج...  \n",
              "1  صح : • تم اعطاء 259 . 530 جرع من لقاح كور • اه...  \n",
              "2  خادم حرم حفظ الله تلقي جرع اولي من لقاح كور كو...  \n",
              "3  صح عالمي : لقاحات كور امن ولا خوف من . . و كوف...  \n",
              "4  وزير صح هال زايد قول ان جري مراجع خطوط انتاج ش...  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dev = pd.read_csv('./Dataset/cleaned_dev.csv')\n",
        "print(df_dev.shape)\n",
        "df_dev.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxYcmG0-Mxbq",
        "outputId": "f12ad80e-2bc5-4737-d067-d66159050dc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "137\n",
            "count    6702.000000\n",
            "mean       25.610564\n",
            "std        14.461046\n",
            "min         2.000000\n",
            "25%        14.000000\n",
            "50%        21.000000\n",
            "75%        37.000000\n",
            "max       137.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "MAX_TWEET_LENGTH = -1\n",
        "for tweet in df_train['cleaned_text']:\n",
        "  tweet_arr = tweet.split(' ')\n",
        "  MAX_TWEET_LENGTH = max(MAX_TWEET_LENGTH, len(tweet_arr))\n",
        "print(MAX_TWEET_LENGTH)\n",
        "print(pd.Series([len(x.split(' ')) for x in df_train['cleaned_text']]).describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "QeQZ4nR-8XBe"
      },
      "outputs": [],
      "source": [
        "def embedded(text):\n",
        "  embedded_text = np.zeros((len(text),MAX_TWEET_LENGTH*100))\n",
        "  print(embedded_text.shape)\n",
        "  for i,tweet in enumerate(text):\n",
        "    sentence_embedding = np.array([[]])\n",
        "    for word in tweet.split(\" \"):\n",
        "      sentence_embedding = np.append(sentence_embedding, ft.get_word_vector(word))\n",
        "    sentence_embedding.resize(MAX_TWEET_LENGTH*100)\n",
        "    embedded_text[i] = sentence_embedding\n",
        "  return embedded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "fDWFQW-n8Qo5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6702, 13700)\n",
            "(991, 13700)\n",
            "(6702, 13700)\n",
            "(991, 13700)\n",
            "(6702,)\n",
            "(991,)\n",
            "(6702,)\n",
            "(991,)\n",
            " 1    5308\n",
            " 0     983\n",
            "-1     411\n",
            "Name: stance, dtype: int64\n",
            " 1    798\n",
            " 0    124\n",
            "-1     69\n",
            "Name: stance, dtype: int64\n",
            "info_news       3478\n",
            "personal         994\n",
            "celebrity        915\n",
            "plan             587\n",
            "unrelated        310\n",
            "others           160\n",
            "requests          98\n",
            "rumors            76\n",
            "advice            67\n",
            "restrictions      17\n",
            "Name: category, dtype: int64\n",
            "info_news       543\n",
            "celebrity       142\n",
            "personal        127\n",
            "plan             82\n",
            "unrelated        34\n",
            "requests         19\n",
            "others           17\n",
            "rumors           15\n",
            "advice           10\n",
            "restrictions      2\n",
            "Name: category, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "x_train = embedded(df_train['cleaned_text'])\n",
        "x_test = embedded(df_dev['cleaned_text'])\n",
        "y_train_stance = df_train['stance']\n",
        "y_test_stance = df_dev['stance']\n",
        "y_train_cat = df_train['category']\n",
        "y_test_cat = df_dev['category']\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train_stance.shape)\n",
        "print(y_test_stance.shape)\n",
        "print(y_train_cat.shape)\n",
        "print(y_test_cat.shape)\n",
        "print(y_train_stance.value_counts())\n",
        "print(y_test_stance.value_counts())\n",
        "print(y_train_cat.value_counts())\n",
        "print(y_test_cat.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PCA \n",
        "# x_train = PCA(n_components=100).fit_transform(x_train)\n",
        "# PCA_test = PCA(n_components=100).fit(x_test_stance)\n",
        "# x_test_stance = PCA_test.transform(x_test_stance)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6702, 13700)\n",
            " 0    5308\n",
            " 1    5308\n",
            "-1    5308\n",
            "Name: stance, dtype: int64\n",
            "restrictions    3478\n",
            "requests        3478\n",
            "rumors          3478\n",
            "plan            3478\n",
            "others          3478\n",
            "celebrity       3478\n",
            "personal        3478\n",
            "advice          3478\n",
            "info_news       3478\n",
            "unrelated       3478\n",
            "Name: category, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Apply SMOTE oversampling to the training data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "x_train_stance, y_train_stance = sm.fit_resample(x_train, y_train_stance)\n",
        "x_train_cat, y_train_cat = sm.fit_resample(x_train, y_train_cat)\n",
        "print(x_train.shape)\n",
        "print(y_train_stance.value_counts())\n",
        "print(y_train_cat.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_stance = np.array(y_train_stance)\n",
        "y_test_stance = np.array(y_test_stance)\n",
        "y_train_cat = np.array(y_train_cat)\n",
        "y_test_cat = np.array(y_test_cat)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TVnpIL2s_eNp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.09      0.15       131\n",
            "           0       0.60      0.12      0.20       304\n",
            "           1       0.81      0.98      0.89      1662\n",
            "\n",
            "    accuracy                           0.80      2097\n",
            "   macro avg       0.62      0.40      0.41      2097\n",
            "weighted avg       0.76      0.80      0.74      2097\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Random Forest on stance\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=2002)\n",
        "clf.fit(x_train_stance, y_train_stance)\n",
        "y_pred = clf.predict(x_test)\n",
        "print(classification_report(y_test_stance, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      advice       0.00      0.00      0.00        20\n",
            "   celebrity       0.76      0.54      0.63       306\n",
            "   info_news       0.57      0.84      0.68      1074\n",
            "      others       0.16      0.09      0.11        35\n",
            "    personal       0.41      0.21      0.28       321\n",
            "        plan       0.19      0.08      0.11       172\n",
            "    requests       0.32      0.23      0.27        30\n",
            "restrictions       0.00      0.00      0.00         8\n",
            "      rumors       0.00      0.00      0.00        24\n",
            "   unrelated       0.46      0.12      0.19       107\n",
            "\n",
            "    accuracy                           0.56      2097\n",
            "   macro avg       0.29      0.21      0.23      2097\n",
            "weighted avg       0.51      0.56      0.51      2097\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Random Forest on category\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=2002)\n",
        "clf.fit(x_train_cat, y_train_cat)\n",
        "y_pred = clf.predict(x_test)\n",
        "print(classification_report(y_test_cat, y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.21      0.29      0.24       131\n",
            "           0       0.32      0.34      0.33       304\n",
            "           1       0.86      0.82      0.84      1662\n",
            "\n",
            "    accuracy                           0.72      2097\n",
            "   macro avg       0.46      0.48      0.47      2097\n",
            "weighted avg       0.74      0.72      0.73      2097\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SVM on stance\n",
        "clf = svm.SVC(kernel='linear', C=1.0, probability=True)\n",
        "clf.fit(x_train_stance, y_train_stance)\n",
        "y_pred = clf.predict(x_test)\n",
        "print(classification_report(y_test_stance, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      advice       0.00      0.00      0.00        20\n",
            "   celebrity       0.59      0.65      0.62       306\n",
            "   info_news       0.64      0.67      0.65      1074\n",
            "      others       0.07      0.09      0.07        35\n",
            "    personal       0.46      0.41      0.43       321\n",
            "        plan       0.20      0.21      0.21       172\n",
            "    requests       0.17      0.23      0.19        30\n",
            "restrictions       0.00      0.00      0.00         8\n",
            "      rumors       0.08      0.04      0.05        24\n",
            "   unrelated       0.27      0.17      0.21       107\n",
            "\n",
            "    accuracy                           0.53      2097\n",
            "   macro avg       0.25      0.25      0.24      2097\n",
            "weighted avg       0.52      0.53      0.52      2097\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# SVM on category\n",
        "clf = svm.SVC(kernel='linear', C=1.0, probability=True)\n",
        "clf.fit(x_train_cat, y_train_cat)\n",
        "y_pred = clf.predict(x_test)\n",
        "print(classification_report(y_test_cat, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15924, 137, 100)\n",
            "(34780, 137, 100)\n",
            "(991, 137, 100)\n"
          ]
        }
      ],
      "source": [
        "x_train_stance = x_train_stance.reshape(x_train_stance.shape[0],MAX_TWEET_LENGTH,100)\n",
        "x_train_cat = x_train_cat.reshape(x_train_cat.shape[0],MAX_TWEET_LENGTH,100)\n",
        "x_test = x_test.reshape(x_test.shape[0],MAX_TWEET_LENGTH,100)\n",
        "print(x_train_stance.shape)\n",
        "print(x_train_cat.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "(15924,)\n",
            "(15924, 3)\n"
          ]
        }
      ],
      "source": [
        "y_train_stance = y_train_stance + 1\n",
        "# squeeze the last dimension of y_train\n",
        "y_train_stance = np.squeeze(y_train_stance)\n",
        "print(y_train_stance[0])\n",
        "print(y_train_stance.shape)\n",
        "y_train_stance = to_categorical(y_train_stance, 3)\n",
        "print(y_train_stance.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "celebrity\n",
            "1.0\n",
            "(34780, 10)\n"
          ]
        }
      ],
      "source": [
        "def map_category_to_int(category):\n",
        "    y_cat = np.zeros(category.shape)\n",
        "    # advice = 0, celebrity = 1, info_news = 2, others = 3, personal = 4, plan = 5, requests = 6, restrictions = 7, rumors = 8, unrelated = 9\n",
        "    for i,cat in enumerate(category):\n",
        "        if cat == 'advice':\n",
        "            y_cat[i] = 0\n",
        "        elif cat == 'celebrity':\n",
        "            y_cat[i] = 1\n",
        "        elif cat == 'info_news':\n",
        "            y_cat[i] = 2\n",
        "        elif cat == 'others':\n",
        "            y_cat[i] = 3\n",
        "        elif cat == 'personal':\n",
        "            y_cat[i] = 4\n",
        "        elif cat == 'plan':\n",
        "            y_cat[i] = 5\n",
        "        elif cat == 'requests':\n",
        "            y_cat[i] = 6\n",
        "        elif cat == 'restrictions':\n",
        "            y_cat[i] = 7\n",
        "        elif cat == 'rumors':\n",
        "            y_cat[i] = 8\n",
        "        elif cat == 'unrelated':\n",
        "            y_cat[i] = 9\n",
        "    return y_cat\n",
        "\n",
        "\n",
        "print(y_train_cat[0])\n",
        "y_train_cat_int = map_category_to_int(y_train_cat)\n",
        "print(y_train_cat_int[0])\n",
        "y_train_cat_int = to_categorical(y_train_cat_int, 10)\n",
        "print(y_train_cat_int.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def map_int_to_category(y_cat):\n",
        "    category = []\n",
        "    for i,cat in enumerate(y_cat):\n",
        "        if cat == 0:\n",
        "            category.append('advice')\n",
        "        elif cat == 1:\n",
        "            category.append('celebrity')\n",
        "        elif cat == 2:\n",
        "            category.append('info_news')\n",
        "        elif cat == 3:\n",
        "            category.append('others')\n",
        "        elif cat == 4:\n",
        "            category.append('personal')\n",
        "        elif cat == 5:\n",
        "            category.append('plan')\n",
        "        elif cat == 6:\n",
        "            category.append('requests')\n",
        "        elif cat == 7:\n",
        "            category.append('restrictions')\n",
        "        elif cat == 8:\n",
        "            category.append('rumors')\n",
        "        elif cat == 9:\n",
        "            category.append('unrelated')\n",
        "    return category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15924, 137, 100)\n",
            "(15924, 3)\n",
            "(34780, 137, 100)\n",
            "(34780,)\n",
            "(34780, 10)\n",
            "(991, 137, 100)\n",
            "(991,)\n",
            "(991,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train_stance.shape)\n",
        "print(y_train_stance.shape)\n",
        "print(x_train_cat.shape)\n",
        "print(y_train_cat.shape)\n",
        "print(y_train_cat_int.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test_stance.shape)\n",
        "print(y_test_cat.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_6 (SimpleRNN)    (None, 137, 100)          20100     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 137, 100)          0         \n",
            "                                                                 \n",
            " simple_rnn_7 (SimpleRNN)    (None, 32)                4256      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,455\n",
            "Trainable params: 24,455\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# RNN model for stance\n",
        "model1_stance = Sequential()\n",
        "# model.add(Input(shape=(137,100)))\n",
        "model1_stance.add(SimpleRNN(units = 100,input_shape=(MAX_TWEET_LENGTH,100),return_sequences=True))\n",
        "model1_stance.add(Dropout(0.2))\n",
        "model1_stance.add(SimpleRNN(units = 32))\n",
        "model1_stance.add(Dropout(0.2))\n",
        "model1_stance.add(Dense(3, activation='softmax'))\n",
        "print(model1_stance.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "498/498 [==============================] - 22s 40ms/step - loss: 0.9839 - accuracy: 0.5139 - precision: 0.6267 - recall: 0.2781\n",
            "Epoch 2/12\n",
            "498/498 [==============================] - 19s 38ms/step - loss: 0.8089 - accuracy: 0.6434 - precision: 0.7051 - recall: 0.5413\n",
            "Epoch 3/12\n",
            "498/498 [==============================] - 19s 38ms/step - loss: 0.6994 - accuracy: 0.7061 - precision: 0.7465 - recall: 0.6468\n",
            "Epoch 4/12\n",
            "498/498 [==============================] - 20s 40ms/step - loss: 0.6282 - accuracy: 0.7427 - precision: 0.7773 - recall: 0.6990\n",
            "Epoch 5/12\n",
            "498/498 [==============================] - 20s 40ms/step - loss: 0.5767 - accuracy: 0.7668 - precision: 0.7959 - recall: 0.7321\n",
            "Epoch 6/12\n",
            "498/498 [==============================] - 19s 38ms/step - loss: 0.5327 - accuracy: 0.7890 - precision: 0.8166 - recall: 0.7590\n",
            "Epoch 7/12\n",
            "498/498 [==============================] - 19s 39ms/step - loss: 0.5001 - accuracy: 0.8006 - precision: 0.8265 - recall: 0.7751\n",
            "Epoch 8/12\n",
            "498/498 [==============================] - 18s 37ms/step - loss: 0.4712 - accuracy: 0.8110 - precision: 0.8321 - recall: 0.7890\n",
            "Epoch 9/12\n",
            "498/498 [==============================] - 21s 41ms/step - loss: 0.4377 - accuracy: 0.8263 - precision: 0.8436 - recall: 0.8063\n",
            "Epoch 10/12\n",
            "498/498 [==============================] - 20s 39ms/step - loss: 0.4203 - accuracy: 0.8360 - precision: 0.8508 - recall: 0.8182\n",
            "Epoch 11/12\n",
            "498/498 [==============================] - 19s 38ms/step - loss: 0.3884 - accuracy: 0.8493 - precision: 0.8622 - recall: 0.8350\n",
            "Epoch 12/12\n",
            "498/498 [==============================] - 20s 40ms/step - loss: 0.3769 - accuracy: 0.8539 - precision: 0.8660 - recall: 0.8387\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2152ab13490>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "opt = Adam(learning_rate=0.0001)\n",
        "model1_stance.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy', 'Precision', 'Recall'])\n",
        "model1_stance.fit(x_train_stance, y_train_stance, epochs=12, batch_size=32, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 1s 19ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.26      0.35      0.30        69\n",
            "           0       0.28      0.44      0.34       124\n",
            "           1       0.89      0.79      0.84       798\n",
            "\n",
            "    accuracy                           0.71       991\n",
            "   macro avg       0.48      0.52      0.49       991\n",
            "weighted avg       0.77      0.71      0.74       991\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model1_stance.predict(x_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_pred = y_pred - 1\n",
        "print(classification_report(y_test_stance, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_8 (SimpleRNN)    (None, 137, 100)          20100     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 137, 100)          0         \n",
            "                                                                 \n",
            " simple_rnn_9 (SimpleRNN)    (None, 32)                4256      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,686\n",
            "Trainable params: 24,686\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# RNN model for category\n",
        "model1_cat = Sequential()\n",
        "# model.add(Input(shape=(137,100)))\n",
        "model1_cat.add(SimpleRNN(units = 100,input_shape=(MAX_TWEET_LENGTH,100),return_sequences=True))\n",
        "model1_cat.add(Dropout(0.2))\n",
        "model1_cat.add(SimpleRNN(units = 32))\n",
        "model1_cat.add(Dropout(0.2))\n",
        "model1_cat.add(Dense(10, activation='softmax'))\n",
        "print(model1_cat.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "1087/1087 [==============================] - 46s 40ms/step - loss: 1.8948 - accuracy: 0.3564 - precision: 0.9551 - recall: 0.0612\n",
            "Epoch 2/12\n",
            "1087/1087 [==============================] - 43s 39ms/step - loss: 1.3993 - accuracy: 0.5508 - precision: 0.9177 - recall: 0.2737\n",
            "Epoch 3/12\n",
            "1087/1087 [==============================] - 41s 38ms/step - loss: 1.1354 - accuracy: 0.6383 - precision: 0.8902 - recall: 0.4334\n",
            "Epoch 4/12\n",
            "1087/1087 [==============================] - 41s 38ms/step - loss: 0.9655 - accuracy: 0.6926 - precision: 0.8803 - recall: 0.5346\n",
            "Epoch 5/12\n",
            "1087/1087 [==============================] - 39s 36ms/step - loss: 0.8515 - accuracy: 0.7260 - precision: 0.8755 - recall: 0.5973\n",
            "Epoch 6/12\n",
            "1087/1087 [==============================] - 38s 35ms/step - loss: 0.7713 - accuracy: 0.7480 - precision: 0.8795 - recall: 0.6408\n",
            "Epoch 7/12\n",
            "1087/1087 [==============================] - 48s 44ms/step - loss: 0.7109 - accuracy: 0.7674 - precision: 0.8806 - recall: 0.6703\n",
            "Epoch 8/12\n",
            "1087/1087 [==============================] - 51s 47ms/step - loss: 0.6568 - accuracy: 0.7852 - precision: 0.8841 - recall: 0.6978\n",
            "Epoch 9/12\n",
            "1087/1087 [==============================] - 48s 44ms/step - loss: 0.6162 - accuracy: 0.7943 - precision: 0.8851 - recall: 0.7165\n",
            "Epoch 10/12\n",
            "1087/1087 [==============================] - 48s 44ms/step - loss: 0.5820 - accuracy: 0.8040 - precision: 0.8878 - recall: 0.7337\n",
            "Epoch 11/12\n",
            "1087/1087 [==============================] - 54s 50ms/step - loss: 0.5530 - accuracy: 0.8121 - precision: 0.8885 - recall: 0.7468\n",
            "Epoch 12/12\n",
            "1087/1087 [==============================] - 62s 57ms/step - loss: 0.5233 - accuracy: 0.8225 - precision: 0.8934 - recall: 0.7595\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x21538ebe880>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "opt = Adam(learning_rate=0.0001)\n",
        "model1_cat.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy', 'Precision', 'Recall'])\n",
        "model1_cat.fit(x_train_cat, y_train_cat_int, epochs=12, batch_size=32, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 1s 15ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      advice       0.03      0.04      0.03        25\n",
            "   celebrity       0.59      0.75      0.66       275\n",
            "   info_news       0.72      0.35      0.47      1051\n",
            "      others       0.05      0.15      0.08        40\n",
            "    personal       0.33      0.33      0.33       283\n",
            "        plan       0.20      0.37      0.26       185\n",
            "    requests       0.04      0.09      0.06        32\n",
            "restrictions       0.00      0.00      0.00         7\n",
            "      rumors       0.05      0.17      0.07        24\n",
            "   unrelated       0.17      0.39      0.24        89\n",
            "\n",
            "    accuracy                           0.39      2011\n",
            "   macro avg       0.22      0.26      0.22      2011\n",
            "weighted avg       0.53      0.39      0.42      2011\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model1_cat.predict(x_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_pred = map_int_to_category(y_pred)\n",
        "print(classification_report(y_test_cat, y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 137, 100)          80400     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 137, 100)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                17024     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 97,523\n",
            "Trainable params: 97,523\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model2_stance = Sequential()\n",
        "# model.add(Input(shape=(137,100)))\n",
        "model2_stance.add(LSTM(units = 100,input_shape=(137,100),return_sequences=True))\n",
        "model2_stance.add(Dropout(0.2))\n",
        "model2_stance.add(LSTM(units = 32))\n",
        "model2_stance.add(Dropout(0.2))\n",
        "model2_stance.add(Dense(3, activation='softmax'))\n",
        "print(model2_stance.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "498/498 - 69s - loss: 1.0990 - accuracy: 0.3389 - precision: 0.0000e+00 - recall: 0.0000e+00 - 69s/epoch - 139ms/step\n",
            "Epoch 2/12\n",
            "498/498 - 65s - loss: 1.0990 - accuracy: 0.3318 - precision: 0.0000e+00 - recall: 0.0000e+00 - 65s/epoch - 130ms/step\n",
            "Epoch 3/12\n",
            "498/498 - 55s - loss: 1.0989 - accuracy: 0.3348 - precision: 0.0000e+00 - recall: 0.0000e+00 - 55s/epoch - 111ms/step\n",
            "Epoch 4/12\n",
            "498/498 - 62s - loss: 1.0987 - accuracy: 0.3367 - precision: 0.0000e+00 - recall: 0.0000e+00 - 62s/epoch - 124ms/step\n",
            "Epoch 5/12\n",
            "498/498 - 65s - loss: 1.0989 - accuracy: 0.3298 - precision: 1.0000 - recall: 6.2798e-05 - 65s/epoch - 131ms/step\n",
            "Epoch 6/12\n",
            "498/498 - 73s - loss: 1.0988 - accuracy: 0.3293 - precision: 1.0000 - recall: 6.2798e-05 - 73s/epoch - 146ms/step\n",
            "Epoch 7/12\n",
            "498/498 - 69s - loss: 1.1001 - accuracy: 0.3297 - precision: 0.3600 - recall: 5.6518e-04 - 69s/epoch - 138ms/step\n",
            "Epoch 8/12\n",
            "498/498 - 55s - loss: 1.0997 - accuracy: 0.3296 - precision: 0.0000e+00 - recall: 0.0000e+00 - 55s/epoch - 111ms/step\n",
            "Epoch 9/12\n",
            "498/498 - 57s - loss: 1.0988 - accuracy: 0.3341 - precision: 0.0000e+00 - recall: 0.0000e+00 - 57s/epoch - 114ms/step\n",
            "Epoch 10/12\n",
            "498/498 - 57s - loss: 1.0988 - accuracy: 0.3315 - precision: 0.0000e+00 - recall: 0.0000e+00 - 57s/epoch - 114ms/step\n",
            "Epoch 11/12\n",
            "498/498 - 71s - loss: 1.0987 - accuracy: 0.3326 - precision: 0.0000e+00 - recall: 0.0000e+00 - 71s/epoch - 143ms/step\n",
            "Epoch 12/12\n",
            "498/498 - 72s - loss: 1.0987 - accuracy: 0.3274 - precision: 0.0000e+00 - recall: 0.0000e+00 - 72s/epoch - 145ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2153c3e3730>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "opt = Adam(learning_rate=0.001)\n",
        "model2_stance.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy', 'Precision', 'Recall'])\n",
        "model2_stance.fit(x_train_stance, y_train_stance, epochs=12, batch_size=32, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66/66 [==============================] - 3s 37ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00       131\n",
            "           0       0.14      1.00      0.25       304\n",
            "           1       0.50      0.00      0.00      1662\n",
            "\n",
            "    accuracy                           0.14      2097\n",
            "   macro avg       0.21      0.33      0.08      2097\n",
            "weighted avg       0.42      0.14      0.04      2097\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred = model2_stance.predict(x_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_pred = y_pred - 1\n",
        "print(classification_report(y_test_stance, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 137, 100)          80400     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 137, 100)          0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 32)                17024     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 97,754\n",
            "Trainable params: 97,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model2_cat = Sequential()\n",
        "# model.add(Input(shape=(137,100)))\n",
        "model2_cat.add(LSTM(units = 100,input_shape=(137,100),return_sequences=True))\n",
        "model2_cat.add(Dropout(0.2))\n",
        "model2_cat.add(LSTM(units = 32))\n",
        "model2_cat.add(Dropout(0.2))\n",
        "model2_cat.add(Dense(10, activation='softmax'))\n",
        "print(model2_cat.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "795/795 [==============================] - 89s 107ms/step - loss: 2.3027 - accuracy: 0.0969 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 2/20\n",
            "795/795 [==============================] - 85s 107ms/step - loss: 2.3026 - accuracy: 0.0983 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 3/20\n",
            "795/795 [==============================] - 85s 107ms/step - loss: 2.3025 - accuracy: 0.0999 - precision: 1.0000 - recall: 3.9339e-05\n",
            "Epoch 4/20\n",
            "795/795 [==============================] - 85s 107ms/step - loss: 2.3022 - accuracy: 0.1005 - precision: 1.0000 - recall: 1.5736e-04\n",
            "Epoch 5/20\n",
            "795/795 [==============================] - 84s 106ms/step - loss: 2.2729 - accuracy: 0.1310 - precision: 0.2500 - recall: 3.9339e-05\n",
            "Epoch 6/20\n",
            "795/795 [==============================] - 84s 106ms/step - loss: 2.0076 - accuracy: 0.2329 - precision: 0.8406 - recall: 0.0776\n",
            "Epoch 7/20\n",
            "795/795 [==============================] - 86s 108ms/step - loss: 1.8218 - accuracy: 0.2952 - precision: 0.9064 - recall: 0.0956\n",
            "Epoch 8/20\n",
            "795/795 [==============================] - 87s 109ms/step - loss: 1.8238 - accuracy: 0.2997 - precision: 0.8748 - recall: 0.0954\n",
            "Epoch 9/20\n",
            "795/795 [==============================] - 89s 112ms/step - loss: 1.6823 - accuracy: 0.3473 - precision: 0.8805 - recall: 0.1058\n",
            "Epoch 10/20\n",
            "795/795 [==============================] - 82s 103ms/step - loss: 1.6328 - accuracy: 0.3705 - precision: 0.8417 - recall: 0.1178\n",
            "Epoch 11/20\n",
            "795/795 [==============================] - 82s 103ms/step - loss: 1.5918 - accuracy: 0.3967 - precision: 0.8159 - recall: 0.1329\n",
            "Epoch 12/20\n",
            "795/795 [==============================] - 80s 101ms/step - loss: 1.5896 - accuracy: 0.4176 - precision: 0.8145 - recall: 0.1314\n",
            "Epoch 13/20\n",
            "795/795 [==============================] - 79s 99ms/step - loss: 1.5539 - accuracy: 0.4440 - precision: 0.7624 - recall: 0.1375\n",
            "Epoch 14/20\n",
            "795/795 [==============================] - 83s 105ms/step - loss: 1.4795 - accuracy: 0.4714 - precision: 0.7463 - recall: 0.1890\n",
            "Epoch 15/20\n",
            "795/795 [==============================] - 85s 107ms/step - loss: 1.4769 - accuracy: 0.4759 - precision: 0.7404 - recall: 0.1884\n",
            "Epoch 16/20\n",
            "795/795 [==============================] - 84s 106ms/step - loss: 1.5942 - accuracy: 0.4272 - precision: 0.6735 - recall: 0.1286\n",
            "Epoch 17/20\n",
            "795/795 [==============================] - 82s 104ms/step - loss: 1.3707 - accuracy: 0.5257 - precision: 0.7393 - recall: 0.2438\n",
            "Epoch 18/20\n",
            "795/795 [==============================] - 81s 102ms/step - loss: 1.6673 - accuracy: 0.3958 - precision: 0.5834 - recall: 0.1183\n",
            "Epoch 19/20\n",
            "795/795 [==============================] - 81s 102ms/step - loss: 1.5073 - accuracy: 0.4566 - precision: 0.6576 - recall: 0.1429\n",
            "Epoch 20/20\n",
            "795/795 [==============================] - 81s 102ms/step - loss: 1.3739 - accuracy: 0.5292 - precision: 0.6943 - recall: 0.2819\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x201f4638ca0>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "opt = Adam(learning_rate=0.0001)\n",
        "model2_cat.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy', 'Precision', 'Recall'])\n",
        "model2_cat.fit(x_train_cat, y_train_cat_int, epochs=12, batch_size=32, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66/66 [==============================] - 3s 37ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      advice       0.01      0.15      0.02        20\n",
            "   celebrity       0.51      0.63      0.56       306\n",
            "   info_news       0.00      0.00      0.00      1074\n",
            "      others       0.04      0.09      0.05        35\n",
            "    personal       0.00      0.00      0.00       321\n",
            "        plan       0.14      0.65      0.23       172\n",
            "    requests       0.05      0.43      0.08        30\n",
            "restrictions       0.00      0.00      0.00         8\n",
            "      rumors       0.03      0.21      0.05        24\n",
            "   unrelated       0.26      0.18      0.21       107\n",
            "\n",
            "    accuracy                           0.17      2097\n",
            "   macro avg       0.10      0.23      0.12      2097\n",
            "weighted avg       0.10      0.17      0.11      2097\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred = model2_cat.predict(x_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_pred = map_int_to_category(y_pred)\n",
        "print(classification_report(y_test_cat, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
